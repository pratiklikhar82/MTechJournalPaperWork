{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: segmentation-models in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: image-classifiers==1.0.0 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from segmentation-models) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications<=1.0.8,>=1.0.7 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from segmentation-models) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: efficientnet==1.0.0 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from segmentation-models) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-image in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation-models) (0.17.2)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4)\n",
      "Requirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2020.7.24)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.1 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.5.0)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\n",
      "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: decorator>=4.3.0 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U albumentations>=0.3.0 --user \n",
    "!pip install -U --pre segmentation-models --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/pratiklikhar/MTech_Project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for data visualization\n",
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "# helper function for data visualization    \n",
    "def denormalize(x):\n",
    "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
    "    x_max = np.percentile(x, 98)\n",
    "    x_min = np.percentile(x, 2)    \n",
    "    x = (x - x_min) / (x_max - x_min)\n",
    "    x = x.clip(0, 1)\n",
    "    return x\n",
    "    \n",
    "\n",
    "# classes for data loading and preprocessing\n",
    "class Dataset:\n",
    "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
    "    \n",
    "    Args:\n",
    "        images_dir (str): path to images folder\n",
    "        masks_dir (str): path to segmentation masks folder\n",
    "        class_values (list): values of classes to extract from segmentation mask\n",
    "        augmentation (albumentations.Compose): data transfromation pipeline \n",
    "            (e.g. flip, scale, etc.)\n",
    "        preprocessing (albumentations.Compose): data preprocessing \n",
    "            (e.g. noralization, shape manipulation, etc.)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    CLASSES = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            images_dir, \n",
    "            masks_dir, \n",
    "            classes=None, \n",
    "            augmentation=None, \n",
    "            preprocessing=None,\n",
    "    ):\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        #print(self.masks_fps)\n",
    "        \n",
    "        # convert str names to class values on masks\n",
    "        self.class_values = [self.CLASSES.index(cls) for cls in classes]\n",
    "        \n",
    "        #print(self.class_values)\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # read data\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(self.masks_fps[i], 0)\n",
    "        #print(mask)\n",
    "        \n",
    "        # extract certain classes from mask (e.g. cars)\n",
    "        masks = [(mask == (v*2)+3) for v in self.class_values]\n",
    "        #for v in self.class_values:\n",
    "        #print(v)\n",
    "        #print(masks)\n",
    "        mask = np.stack(masks, axis=-1).astype('float')\n",
    "        #print(mask)\n",
    "        \n",
    "        # add background if mask is not binary\n",
    "        if mask.shape[-1] != 1:\n",
    "            background = 1 - mask.sum(axis=-1, keepdims=True)\n",
    "            mask = np.concatenate((mask, background), axis=-1)\n",
    "        \n",
    "        # apply augmentations\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        # apply preprocessing\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "            \n",
    "        return image, mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    \n",
    "class Dataloder(keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        # transpose list of lists\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'resnet101'\n",
    "BATCH_SIZE = 2\n",
    "CLASSES = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "LR = 0.0001\n",
    "EPOCHS = 40\n",
    "\n",
    "preprocess_input = sm.get_preprocessing(BACKBONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/pratiklikhar/anaconda3/envs/pratik/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define network parameters\n",
    "n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\n",
    "activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
    "\n",
    "#create model\n",
    "model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optomizer\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
    "#dice_loss = sm.losses.DiceLoss(class_weights=np.array([1, 2, 0.5])) \n",
    "focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
    "#total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model.compile(optim, focal_loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_model1.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import datetime\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as py\n",
    "%matplotlib inline\n",
    "\n",
    "def showVideo():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "    print(cap.isOpened())\n",
    "    print(cap.read())\n",
    "    cap.set(3, 720)   #480 #720 #1280\n",
    "    cap.set(4, 480)   #320 #480 #720\n",
    "    fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    out = cv2.VideoWriter('output.avi', fourcc, 5.0, (int(cap.get(3)),int(cap.get(4))))\n",
    "    try:\n",
    "        while(cap.isOpened()):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                # Release the Video Device if ret is false\n",
    "                cap.release()\n",
    "                # Message to be displayed after releasing the device\n",
    "                print (\"Released Video Resource\")\n",
    "                break\n",
    "            #print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            #print(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            #print(cap.get(3))\n",
    "            #print(cap.get(4))\n",
    "            #out.write(frame)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, (640,480))\n",
    "            #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = np.expand_dims(frame, axis=0)\n",
    "            pr_mask = model.predict(frame)\n",
    "            highind = 0\n",
    "            secondhighind = 0\n",
    "            high = 0\n",
    "            secondhigh = -1\n",
    "            for i in range(37):\n",
    "                addn = np.sum(pr_mask[..., i][0:480][0:640])\n",
    "                if i == 0:\n",
    "                    if addn > high:\n",
    "                        high = addn\n",
    "                        highind = i\n",
    "                        secondhigh = addn\n",
    "                        secondhighind = i\n",
    "                else:\n",
    "                    if addn > high:\n",
    "                        secondhigh = high\n",
    "                        secondhighind = highind\n",
    "                        high = addn\n",
    "                        highind = i\n",
    "                    elif addn > secondhigh and addn < high:\n",
    "                        secondhigh = addn\n",
    "                        secondhighind = i\n",
    "            print(secondhighind)\n",
    "            if secondhighind == 0:\n",
    "                text = '0'\n",
    "            elif secondhighind == 1:\n",
    "                text = '1'\n",
    "            elif secondhighind == 2:\n",
    "                text = '2'\n",
    "            elif secondhighind == 3:\n",
    "                text = '3'\n",
    "            elif secondhighind == 4:\n",
    "                text = '4'\n",
    "            elif secondhighind == 5:\n",
    "                text = '5'\n",
    "            elif secondhighind == 6:\n",
    "                text = '6'\n",
    "            elif secondhighind == 7:\n",
    "                text = '7'\n",
    "            elif secondhighind == 8:\n",
    "                text = '8'\n",
    "            elif secondhighind == 9:\n",
    "                text = '9'\n",
    "            elif secondhighind == 10:\n",
    "                text = 'A'\n",
    "            elif secondhighind == 11:\n",
    "                text = 'B'\n",
    "            elif secondhighind == 12:\n",
    "                text = 'C'\n",
    "            elif secondhighind == 13:\n",
    "                text = 'D'\n",
    "            elif secondhighind == 14:\n",
    "                text = 'E'\n",
    "            elif secondhighind == 15:\n",
    "                text = 'F'\n",
    "            elif secondhighind == 16:\n",
    "                text = 'G'\n",
    "            elif secondhighind == 17:\n",
    "                text = 'H'\n",
    "            elif secondhighind == 18:\n",
    "                text = 'I'\n",
    "            elif secondhighind == 19:\n",
    "                text = 'J'\n",
    "            elif secondhighind == 20:\n",
    "                text = 'K'\n",
    "            elif secondhighind == 21:\n",
    "                text = 'L'\n",
    "            elif secondhighind == 22:\n",
    "                text = 'M'\n",
    "            elif secondhighind == 23:\n",
    "                text = 'N'\n",
    "            elif secondhighind == 24:\n",
    "                text = 'O'\n",
    "            elif secondhighind == 25:\n",
    "                text = 'P'\n",
    "            elif secondhighind == 26:\n",
    "                text = 'Q'\n",
    "            elif secondhighind == 27:\n",
    "                text = 'R'\n",
    "            elif secondhighind == 28:\n",
    "                text = 'S'\n",
    "            elif secondhighind == 29:\n",
    "                text = 'T'\n",
    "            elif secondhighind == 30:\n",
    "                text = 'U'\n",
    "            elif secondhighind == 31:\n",
    "                text = 'V'\n",
    "            elif secondhighind == 32:\n",
    "                text = 'W'\n",
    "            elif secondhighind == 33:\n",
    "                text = 'X'\n",
    "            elif secondhighind == 34:\n",
    "                text = 'Y'\n",
    "            elif secondhighind == 35:\n",
    "                text = 'Z'\n",
    "            else:\n",
    "                text = 'NA'\n",
    "            frame = frame.squeeze()\n",
    "            # Turn off the axis\n",
    "            py.axis('off')\n",
    "            # Title of the window\n",
    "            py.title(\"Input Stream\")\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            #text = 'Width: '+ str(cap.get(3)) +' Height: '+ str(cap.get(4))\n",
    "            datet = str(datetime.datetime.now())\n",
    "            frame = cv2.putText(frame, text, (10,50), font, 1, (0,255,255), 2, cv2.LINE_AA)\n",
    "            out.write(frame)\n",
    "            # Display the frame\n",
    "            py.imshow(frame)\n",
    "            py.show()\n",
    "            # Display the frame until new frame is available\n",
    "            display.clear_output(wait=True)\n",
    "    except KeyboardInterrupt:\n",
    "        # Release the Video Device\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        # Message to be displayed after releasing the device\n",
    "        print(\"Released Video Resource\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n"
     ]
    }
   ],
   "source": [
    "showVideo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "7\n",
      "7\n",
      "33\n",
      "7\n",
      "4\n",
      "7\n",
      "4\n",
      "7\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "31\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "32\n",
      "32\n",
      "18\n",
      "20\n",
      "31\n",
      "31\n",
      "31\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(0) \n",
    "  \n",
    "while(True): \n",
    "      \n",
    "    # Capture the video frame \n",
    "    # by frame \n",
    "    ret, frame = vid.read() \n",
    "  \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (640,480))\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = np.expand_dims(frame, axis=0)\n",
    "    pr_mask = model.predict(frame)\n",
    "    highind = 0\n",
    "    secondhighind = 0\n",
    "    high = 0\n",
    "    secondhigh = -1\n",
    "    for i in range(37):\n",
    "        addn = np.sum(pr_mask[..., i][0:480][0:640])\n",
    "        if i == 0:\n",
    "            if addn > high:\n",
    "                high = addn\n",
    "                highind = i\n",
    "                secondhigh = addn\n",
    "                secondhighind = i\n",
    "        else:\n",
    "            if addn > high:\n",
    "                secondhigh = high\n",
    "                secondhighind = highind\n",
    "                high = addn\n",
    "                highind = i\n",
    "            elif addn > secondhigh and addn < high:\n",
    "                secondhigh = addn\n",
    "                secondhighind = i\n",
    "    print(secondhighind)\n",
    "    if secondhighind == 0:\n",
    "        text = '0'\n",
    "    elif secondhighind == 1:\n",
    "        text = '1'\n",
    "    elif secondhighind == 2:\n",
    "        text = '2'\n",
    "    elif secondhighind == 3:\n",
    "        text = '3'\n",
    "    elif secondhighind == 4:\n",
    "        text = '4'\n",
    "    elif secondhighind == 5:\n",
    "        text = '5'\n",
    "    elif secondhighind == 6:\n",
    "        text = '6'\n",
    "    elif secondhighind == 7:\n",
    "        text = '7'\n",
    "    elif secondhighind == 8:\n",
    "        text = '8'\n",
    "    elif secondhighind == 9:\n",
    "        text = '9'\n",
    "    elif secondhighind == 10:\n",
    "        text = 'A'\n",
    "    elif secondhighind == 11:\n",
    "        text = 'B'\n",
    "    elif secondhighind == 12:\n",
    "        text = 'C'\n",
    "    elif secondhighind == 13:\n",
    "        text = 'D'\n",
    "    elif secondhighind == 14:\n",
    "        text = 'E'\n",
    "    elif secondhighind == 15:\n",
    "        text = 'F'\n",
    "    elif secondhighind == 16:\n",
    "        text = 'G'\n",
    "    elif secondhighind == 17:\n",
    "        text = 'H'\n",
    "    elif secondhighind == 18:\n",
    "        text = 'I'\n",
    "    elif secondhighind == 19:\n",
    "        text = 'J'\n",
    "    elif secondhighind == 20:\n",
    "        text = 'K'\n",
    "    elif secondhighind == 21:\n",
    "        text = 'L'\n",
    "    elif secondhighind == 22:\n",
    "        text = 'M'\n",
    "    elif secondhighind == 23:\n",
    "        text = 'N'\n",
    "    elif secondhighind == 24:\n",
    "        text = 'O'\n",
    "    elif secondhighind == 25:\n",
    "        text = 'P'\n",
    "    elif secondhighind == 26:\n",
    "        text = 'Q'\n",
    "    elif secondhighind == 27:\n",
    "        text = 'R'\n",
    "    elif secondhighind == 28:\n",
    "        text = 'S'\n",
    "    elif secondhighind == 29:\n",
    "        text = 'T'\n",
    "    elif secondhighind == 30:\n",
    "        text = 'U'\n",
    "    elif secondhighind == 31:\n",
    "        text = 'V'\n",
    "    elif secondhighind == 32:\n",
    "        text = 'W'\n",
    "    elif secondhighind == 33:\n",
    "        text = 'X'\n",
    "    elif secondhighind == 34:\n",
    "        text = 'Y'\n",
    "    elif secondhighind == 35:\n",
    "        text = 'Z'\n",
    "    else:\n",
    "        text = 'NA'\n",
    "    frame = frame.squeeze()\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    frame = cv2.putText(frame, text, (10,50), font, 1, (0,255,255), 2, cv2.LINE_AA)\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('frame', frame) \n",
    "      \n",
    "    # the 'q' button is set as the \n",
    "    # quitting button you may use any \n",
    "    # desired button of your choice \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "  \n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
